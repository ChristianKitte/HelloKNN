{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN sklearn",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp2TV1gxGH+5mspaEdUtmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristianKitte/HelloKNN/blob/main/KNN_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxU_43JZFd0h"
      },
      "source": [
        "**Die eigentliche Lösung der Aufgabe ist ganz am Ende zu finden...**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sK6MQJFKHJM"
      },
      "source": [
        "#https://www.python-course.eu/k_nearest_neighbor_sklearn.php"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opz0SlN3BgHE"
      },
      "source": [
        "Im ersten Schritt importiere ich alle im folgenden benötigten Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEmNBwTysIVh",
        "outputId": "c93f1a18-5394-428f-860d-8e67f3fae607"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Bibliotheken importiert....\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bibliotheken importiert....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkR8djMMBob_"
      },
      "source": [
        "Um den Code übersichtlicher zu halten, lagere ich die Funktionalität für die Normalisierung in eine eigene Funktion aus. Ich verwende hierbei den Algorithmus von sklearn mit der Normierungsmethode \"max\". Es scheint, dass dieser im einfachsten Fall einfach alles durch den maximalen Wert teilt. Hierdurch ist der größte Wert 1, der kleinste geht gegen 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GQ0gQFg85fJ",
        "outputId": "f5ced476-a78b-41b5-c7e3-b544b4f71c24"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "# sklearn teilt die Werte enfach durch max, wie es hier scheint (zumindest bei den verwendeten Paramter \"max\")\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler=0\n",
        "\n",
        "def normalizeDataSklearn(values):\n",
        "  # normalized_array = preprocessing.normalize(values, axis=0,norm=\"max\")\n",
        "  \n",
        "  global scaler\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler.fit(values)\n",
        "  \n",
        "  normalized_array = scaler.transform(values)\n",
        "\n",
        "  #print(normalized_array)\n",
        "  return normalized_array\n",
        "\n",
        "print(\"Funktion normalizeDataSklearn wurde erstellt....\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Funktion normalizeDataSklearn wurde erstellt....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYs95RTDCXYk"
      },
      "source": [
        "Als nächstes teile ich das dataset in Test- und Trainingsdaten. Dies habe ich in der vorhergehenden Übung (Regression) noch nicht gemacht. Es scheint mir aber mittlerweile auch bei den Übungen sinnvoll, da nebenbei auch das dataset durchgemischt wird. (Auch wenn es bei KNN nicht notwendig scheint, da gegen alle vorhandenen Elemente gerechnet wird)\n",
        "\n",
        "Ich erstelle hierbei zwei Versionen. Eine ohne vorhergehende Normalisierung, eine mit. Bei KNN ist die Normalisierung vor allem bei großen Differenzen innerhalb der Zahlenbereich notwendig, um ein shadowing vorzubeugen.\n",
        "\n",
        "Bei dem IRIS Datensatz halte ich dies aber für noch nicht notwendig."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmgaOBNmsJYl",
        "outputId": "b9cb627d-63d9-4dc8-ac6c-9210742c61e5"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
        "# 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'],\n",
        "# 'target_names': ['setosa', 'versicolor', 'virginica'] mit 0, 1, 2 \n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "# Split arrays or matrices into random train and test subsets ==> Es erfolgt ein Shuffle, daher alleine \n",
        "# schon deswegen sinnvoll! randdom_state ermöglicht Replizierbarkeit. Rückgabe ist ein Array mit den\n",
        "# Arrays.\n",
        "\n",
        "ds = datasets.load_iris()\n",
        "data=ds.data\n",
        "labels=ds.target\n",
        "\n",
        "dataNorm = normalizeDataSklearn(data)\n",
        "resArrayNorm = train_test_split(dataNorm, labels, train_size=0.8, test_size=0.2, random_state=1)\n",
        "trainDataNorm, testDataNorm, trainLabels, testLabels = resArrayNorm \n",
        "#print(dataNorm)\n",
        "#print(data)\n",
        "\n",
        "resArray = train_test_split(data, labels, train_size=0.8, test_size=0.2, random_state=1)\n",
        "trainData, testData, trainLabels, testLabels = resArray \n",
        "\n",
        "#ds\n",
        "#labels\n",
        "#target\n",
        "\n",
        "#print(trainData)\n",
        "#print(trainLabels)\n",
        "\n",
        "print(\"Daten vorhanden und vorbereitet\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daten vorhanden und vorbereitet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_bgEka4Dl-Y"
      },
      "source": [
        "Nachdem alle Daten vorbereitet sind, trainiere ich analog zu oben zwei Klassifizierer (einmal mit normalisierten Daten, einmal ohne)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWZ1SB0i0VOt",
        "outputId": "24357603-1ff7-4097-e89f-7db84e78d510"
      },
      "source": [
        "knnClassifier = KNeighborsClassifier(algorithm=\"auto\",\n",
        "                                     metric='euclidean',\n",
        "                                     n_neighbors=8)\n",
        "knnClassifier.fit(trainData, trainLabels)\n",
        "\n",
        "knnClassifierNorm = KNeighborsClassifier(algorithm=\"auto\",\n",
        "                                     metric='euclidean',\n",
        "                                     n_neighbors=8)\n",
        "knnClassifierNorm.fit(trainDataNorm, trainLabels) \n",
        "\n",
        "print(\"Klassifizierer ist vorbereitet and antrainiert\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Klassifizierer ist vorbereitet and antrainiert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZYgGLyoEIko"
      },
      "source": [
        "Abschließend führe ich mit beiden Klassifizierer Vorhersagen aus. Einmal über die Testdaten, einmal über die Trainingsdaten und einmal über alle Daten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdMLqcAf3pir",
        "outputId": "67872576-4f88-4f72-fca1-dd0acf153673"
      },
      "source": [
        "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
        "# \"...the set of labels predicted for a sample must exactly match...\"\n",
        "\n",
        "predLabelsTest = knnClassifier.predict(testData)\n",
        "predLabelsTrain = knnClassifier.predict(trainData)\n",
        "predLabelsAll = knnClassifier.predict(data)\n",
        "\n",
        "predLabelsTestNorm = knnClassifierNorm.predict(scaler.transform(testData))\n",
        "predLabelsTrainNorm = knnClassifierNorm.predict(scaler.transform(trainData))\n",
        "predLabelsAllNorm = knnClassifierNorm.predict(scaler.transform(data))\n",
        "\n",
        "#print(\"Vorhersage:\")\n",
        "#print(predLabelsTest)\n",
        "#print(predLabelsTrain)\n",
        "#print(predLabelsAll)\n",
        "\n",
        "#print(\"Originalwerte:\")\n",
        "#print(testLabels)\n",
        "#print(trainLabels)\n",
        "#print(labels)\n",
        "\n",
        "print()\n",
        "print(\"Accuracy Testdaten: \", accuracy_score(predLabelsTest, testLabels))\n",
        "print(\"Accuracy Trainingsdaten: \", accuracy_score(predLabelsTrain, trainLabels))\n",
        "print(\"Accuracy alle Daten: \", accuracy_score(predLabelsAll, labels))\n",
        "\n",
        "print()\n",
        "print(\"Accuracy (mit Normierung) Testdaten: \", accuracy_score(predLabelsTestNorm, testLabels))\n",
        "print(\"Accuracy (mit Normierung) Trainingsdaten: \", accuracy_score(predLabelsTrainNorm, trainLabels))\n",
        "print(\"Accuracy (mit Normierung) alle Daten: \", accuracy_score(predLabelsAllNorm, labels))\n",
        "\n",
        "print()\n",
        "print(\"Fertig...\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy Testdaten:  1.0\n",
            "Accuracy Trainingsdaten:  0.9833333333333333\n",
            "Accuracy alle Daten:  0.9866666666666667\n",
            "\n",
            "Accuracy (mit Normierung) Testdaten:  1.0\n",
            "Accuracy (mit Normierung) Trainingsdaten:  0.9666666666666667\n",
            "Accuracy (mit Normierung) alle Daten:  0.9733333333333334\n",
            "\n",
            "Fertig...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snx0UWW9-GRx"
      },
      "source": [
        "Die Ergebniss mit und ohne Normierung unterscheiden sich ein wenig, wobei die ohne etwas besser sind:\n",
        "\n",
        "* Accuracy Testdaten:  1.0\n",
        "* Accuracy Trainingsdaten:  0.9833333333333333\n",
        "* Accuracy alle Daten:  0.9866666666666667\n",
        "---\n",
        "\n",
        "* Accuracy (mit Normierung) Testdaten:  1.0\n",
        "* Accuracy (mit Normierung) Trainingsdaten:  0.9666666666666667\n",
        "* Accuracy (mit Normierung) alle Daten:  0.9733333333333334\n",
        "\n",
        "Dies bestätigt meine oben gemachte Vermutung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4IwqoXhE7fT"
      },
      "source": [
        "Nach Abschluss der Vorbereitungen (und einigen Experimenten) komme ich nun zur Lösung der zweiten Aufgabe der 10. EA - Instanzbasiertes Lernen:\n",
        "\n",
        "**Aufgabe:**\n",
        "\n",
        "In the logistic regression example, I gave you a new iris data:\n",
        "4.8,2.5,5.3,2.4\n",
        "\n",
        "Please classify this flower using KNN.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HEmVMhn5AE4",
        "outputId": "b2afd330-5b4b-4167-bb90-cfdcf0c6dae7"
      },
      "source": [
        "values=np.array([4.8,2.5,5.3,2.4])\n",
        "\n",
        "pred = knnClassifier.predict(values.reshape(-1,4))\n",
        "predNorm = knnClassifier.predict(values.reshape(-1,4))\n",
        "\n",
        "#'target_names': ['setosa', 'versicolor', 'virginica'] mit 0, 1, 2 \n",
        "\n",
        "print(pred)\n",
        "print(predNorm)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNdTPfW-G7Mb"
      },
      "source": [
        "**Lösung** \n",
        "\n",
        "Beide Klassifizierer sagen für das unbekannt Element vorher, dass es sich um eine Iris Virginica handelt. Hiermit wird auch das Ergebnis aus der Übung zur Regression bestätigt."
      ]
    }
  ]
}