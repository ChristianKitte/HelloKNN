{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN Algorithmus",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfUMp4hpOXAcXKvQ0JJGhF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristianKitte/HelloKNN/blob/main/KNN_Algorithmus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dfVQYbzKTEs"
      },
      "source": [
        "**Die eigentliche Lösung der Aufgabe ist ganz am Ende zu finden...**\n",
        "\n",
        "Ein interssanter Link zum Thema Datenvorbereitung:\n",
        "\n",
        "\n",
        "https://cloud.google.com/architecture/data-preprocessing-for-ml-with-tf-transform-pt1?hl=de\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Der erste Teil der anstehenden Aufgabe zum Thema instanzabsiertes Lernen ist die Programmierung eines eigenen Logarithmus hierzu. Teile des folgenden Codes beinhalten Alternativen mit Sklearn oder Tests, um Vergleiche mit meiner eigenen Lösung anzustellen. \n",
        "\n",
        "Diese wurden in der Abgabe belassen, da diese auch für mich selbst als NAchschlagewerk dient.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In einem ersten Schritt erfolgen alle notwendigen Importe für die spätere Nutzung:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr3Yb6Mhkpfp",
        "outputId": "0a2ff040-2046-428c-e83c-8c9123c2efbc"
      },
      "source": [
        "# Initialize\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "#from scipy import stats\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "print(\"Import wurde ausgeführt....\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import wurde ausgeführt....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iivi56fvX_kz"
      },
      "source": [
        "Um über eigene Adressen zu verfügen, wird anschließend eine kleine Adressbasis definiert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ryfohiiNur",
        "outputId": "ed3fc0ab-b19b-41a0-d66a-14dc8f8488c8"
      },
      "source": [
        "#Testdaten\n",
        "\n",
        "testdaten=[1,4,2,3426,345,44,3453,7]\n",
        "#testdaten=[1,2,3,4,5,6]\n",
        "#testdaten=[1000,765,800]\n",
        "\n",
        "print(\"Testdaten erzeugt...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testdaten erzeugt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhDa2TC0Yhar"
      },
      "source": [
        "Als Basis dieser Übung dient der auch schon in der Übung zur Regression eingesetzte eigene CSV Datensatz. Im fiktiven Kontext der Nutzung wurde beschlossen, aus den Zahlen der Zuteilungen und erfolgreihen Bearbeitung (siehe hierzu die Ausführungen im Rahmen der Aufgabe zur Regression) einen Quotionen zu berechnen und darauf basierend die Mitarbeiter zu klassifizieren. \n",
        "\n",
        "Es wurden vier Klassen auf Basis der vorliegenden \"Basisdaten\" definiert:\n",
        "* 0 unbestimmt      unbestimmt\n",
        "* 1 Top             =1\n",
        "* 2 Best            >1\n",
        "* 3 Score           >=1.2\n",
        "* 4 Underscore      >=2\n",
        "\n",
        "(Hierbei ist es natürlich diskussionswürdig, ob diese Art zum einen das Verhältnis belastet, zum anderen in dieser Einfachheit sinnvoll ist. Stichwort feature enginiering)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In der folgenden Zelle werden die erweiterten Daten aus GitHub geholt und aufgeteilt. Sie werden nicht gesplittet und ndurcheinander gemischt, da dieser Algorithmus grundsätzlcih alle Daten nutzt und determinstisch/nachvollziehbar ist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2V7jt42DsPv",
        "outputId": "4668d872-ff17-4423-ed88-56f0e938857f"
      },
      "source": [
        "# Daten von GitHub besorgen und Überschriften zur besseren Übersicht anpassen\n",
        "\n",
        "ds=pd.read_csv(\"https://raw.githubusercontent.com/ChristianKitte/HelloKNN/main/Auftraege.csv\")\n",
        "ds=ds.rename(columns={\"Anzahl angenommene Aufträge\":\"Aufträge\",\"Anzahl erfolgreiche Ausführung\":\"erfolgreich\", \"Angenommen durch Erfolg\":\"Faktor\", \"Klasse\":\"Label\"})\n",
        "\n",
        "# Es wurden vier Klassen auf Basis der vorliegenden \"Basisdaten\" definiert:\n",
        "# 0 unbestimmt      unbestimmt\n",
        "# 1 Top             =1\n",
        "# 2 Best            >1\n",
        "# 3 Score           >=1.2\n",
        "# 4 Underscore      >=2\n",
        "\n",
        "# X (Aufträge), Y (Anzahl erfolgreich), labels (Klassen)\n",
        "x = ds.iloc[:,0].values\n",
        "y = ds.iloc[:,1].values\n",
        "data=ds.iloc[:,:2].values # Col 0 und 1 ==> Angabe ist exklusiv !\n",
        "\n",
        "# labels (Klassen)\n",
        "label = ds.iloc[:,3].values\n",
        "\n",
        "print(\"Daten wurden geholt und vorbereitet...\")\n",
        "\n",
        "#print(\"\")\n",
        "#ds\n",
        "#data\n",
        "#label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daten wurden geholt und vorbereitet...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ8wnsqXa0D9"
      },
      "source": [
        "Ein wichtiger Punkt bei instanzbasierten Verfahren ist die Normalisierung. Als Vergleich habe ich hier eine Lösung mit Sklearn umgesetzt, welche ich jedoch nur zum Testen gebraucht haben."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2TXfggWsUK2",
        "outputId": "73d836c0-f121-40d0-87bd-2a64764ac67f"
      },
      "source": [
        "# Wert geteilt durch Max.\n",
        "def normalizeDataSklearn(values):\n",
        "  normalized_array = preprocessing.normalize(values, axis=0,norm=\"max\")\n",
        "\n",
        "  #print(normalized_array)\n",
        "  return normalized_array\n",
        "\n",
        "print(\"Funktion normalizeDataSklearn wurde erstellt...\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Funktion normalizeDataSklearn wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWNzGb7Ja3Mn"
      },
      "source": [
        "Im folgenden ist meine eigene Methode, welche ich auch hier verwenden habe. Ich nutze heirbei globale Variablen, da ich nicht nur die Daten, sondern auch eine neue Instanz Normalisieren muss. Hierfür dient die Funktion normalizeSingleData, welch enur einen Wert normalisert im Gegensatz zu normalizeData."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiMPATuEjChH",
        "outputId": "0ddc0c45-d5f8-4a01-d10d-922634081d63"
      },
      "source": [
        "# Normalisiert zwischen 0 und 1\n",
        "minValue=0           # ==> werden später gebraucht\n",
        "maxValue=0           # ==> werden später gebraucht\n",
        "max_minus_min=0      # ==> werden später gebraucht\n",
        "\n",
        "def normalizeSingleData(value):\n",
        "  return float((value-minValue)/max_minus_min)\n",
        "\n",
        "def normalizeData(values):\n",
        "  global minValue # ==> werden später gebraucht, siehe oben\n",
        "  minValue=np.min(values)\n",
        "  global maxValue # ==> werden später gebraucht, siehe oben\n",
        "  maxValue=np.max(values)\n",
        "  global max_minus_min # ==> werden später gebraucht, siehe oben\n",
        "  max_minus_min=maxValue-minValue\n",
        "\n",
        "  minValuex=minValue\n",
        "\n",
        "  normalizedValues =np.empty(0)\n",
        "\n",
        "  for curValue in values:\n",
        "    normValue=float((curValue-minValue)/max_minus_min)\n",
        "    normalizedValues=np.append(normalizedValues,normValue)\n",
        "\n",
        "  #print(normalizedValues)\n",
        "  return normalizedValues\n",
        "\n",
        "print(\"Funktion normalizeData wurde erstellt...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Funktion normalizeData wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSfFD-50G-Bq"
      },
      "source": [
        "Ab hier fange ich an, die Logig für die Entfernungsberechnung zu bauen. Auch hier setze ich zunächst eine (interessante) Lösung von Sklearn an.\n",
        "\n",
        "Wenn np.linalg.norm() auf einer array-ähnlichen Eingabe ohne zusätzliche Argumente aufgerufen wird, ist das Standardverhalten, die L2-Norm auf einer abgeflachten Ansicht des Arrays zu berechnen. Dies ist die Quadratwurzel aus der Summe der quadrierten Elemente und kann als die Länge des Vektors im euklidischen Raum interpretiert werden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_EMIZZxCmRq",
        "outputId": "836872bf-5e76-42a1-f3af-0730d057e020"
      },
      "source": [
        "#https://www.delftstack.com/de/api/numpy/python-numpy-numpy.linalg.norm-function/\n",
        "#https://www.educative.io/edpresso/what-is-the-nplinalgnorm-method-in-numpy\n",
        "#https://sparrow.dev/numpy-norm/\n",
        "\n",
        "def calculateDistanceSklearn(instance1, instance2):\n",
        "    # just in case, if the instances are lists or tuples:\n",
        "    instance1 = np.array(instance1) \n",
        "    instance2 = np.array(instance2)\n",
        "    \n",
        "    return np.linalg.norm(instance1 - instance2)\n",
        "\n",
        "#print(calculateDistanceSklearn([1, 4, 2, 5], [3, 7, 4, 1]))\n",
        "print(calculateDistanceSklearn([1, 3], [2, 6]))\n",
        "print(\"Funktion calculateDistanceSklearn wurde erstellt...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.1622776601683795\n",
            "Funktion calculateDistanceSklearn wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwQU30PdccIY"
      },
      "source": [
        "Um solch eine Funktion auch mal selbst umzusetzen, habe ich die Funktionalität für zwei dimensionale Daten mal selbst programmiert und verwende ihn auch für meine Lösung.\n",
        "\n",
        "Beide algorithmen liefern heirbei anhand von Testdaten gleiche Ergebnisse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQsCNGXFP5o",
        "outputId": "349d79a3-7fcc-4715-ba7d-a31e304f77f8"
      },
      "source": [
        "def calculateDistance2D(instance1, instance2):\n",
        "  instance1 = np.array(instance1) \n",
        "  instance2 = np.array(instance2)\n",
        "\n",
        "  v_ges=0\n",
        "\n",
        "  for x in range(2):\n",
        "    v_ges=v_ges + pow(instance1[x]-instance2[x],2)\n",
        "\n",
        "  return math.sqrt(v_ges)\n",
        "\n",
        "# x= calculateDistance2D([1,3],[2,6])\n",
        "print(x)\n",
        "print(\"Funktion calculateDistance wurde erstellt...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.1622776601683795\n",
            "Funktion calculateDistance wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SzJSc13c4h7"
      },
      "source": [
        "Die folgende Zelle dient dafür, meinen Datenbestand zu normalisieren (anhand der weiter oben definierten Funktion).\n",
        "\n",
        "Ab hier habe ich zwei Sätze mit normalisierten Daten: \n",
        "\n",
        "Einmal anhand meiner eigenen Funktion und einmal mit Hilfe von Sklearn. Auch hier will ich die Daten später zum Testen nutzen. Zudem ist der mit meinen Code normalisierte Satz um den label/Klasse erweitert. Dies macht den späteren Zugriff einfacher."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLTHmJE4kdwI",
        "outputId": "3ef30aed-571e-42ff-ae30-09ad19c3b6aa"
      },
      "source": [
        "x=np.array(data[:,0]).reshape(-1, 1)\n",
        "y=np.array(data[:,1]).reshape(-1, 1)\n",
        "\n",
        "data_norm_sklearn=normalizeDataSklearn(data)\n",
        "\n",
        "data_norm_x=normalizeData(x)\n",
        "data_norm_y=normalizeData(y)\n",
        "data_norm=np.array([[x,y,l] for x,y,l in zip(data_norm_x,data_norm_y,label)])\n",
        "\n",
        "#print(minValuex)\n",
        "#print(maxValue)\n",
        "#print(max_minus_min)\n",
        "#print(\"\")\n",
        "\n",
        "print(\"Daten wurden normalisiert...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daten wurden normalisiert...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTFnA9fLdbBy"
      },
      "source": [
        "Hier kommt der Kern des Algorithmuses. Ihm wird eine zwei dimensionale Instanz übergeben und zudem ein k. Er prüft die neue Instanz an alle vorhandene Werte und liefert eine sortierte Liste der Entfernungen und Klassen der Länge k zurück."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOhfOAXIxv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eacb08d-0f19-4b04-8e0f-cb36210dcd53"
      },
      "source": [
        "def get_k_nearest(newInstance2D, k):\n",
        "  # Ich verzichte auf ein Splitten der Daten, da bei der hier vorgestellten Lösung \n",
        "  # eine neue Instanz immer gegen alle anderen getestet wird\n",
        "\n",
        "  entfernung_klasse = []\n",
        "  for x in data_norm:\n",
        "    y= calculateDistance2D(x,newInstance2D)\n",
        "    entfernung_klasse.append([y,x[2]])\n",
        "    \n",
        "  entfernung_klasse.sort(key=lambda x: x[0])\n",
        "  return entfernung_klasse[:k+1]\n",
        "\n",
        "print(\"Funktion get_k_nearest wurde erstellt...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Funktion get_k_nearest wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR7pKblEBqkm"
      },
      "source": [
        "Die folgende Methode zählt mir die Anzahl der labels in meinen k-stelligen Ergebnis aus. Die umsetzung ist etwas tricky, dafür habe ich die Bibliothek/das Object defaultdict entdeckt und verwendet.\n",
        "\n",
        "https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\n",
        "\n",
        " \"Usually, a Python dictionary throws a KeyError if you try to get an item with a key that is not currently in the dictionary. The defaultdict in contrast will simply create any items that you try to access (provided of course they do not exist yet).\" \n",
        "\n",
        "Mit Hilfe dieser Methode erhalte ich dynamische eine Auszählung der Instanzen zu den einzelnen Labeln. Diese muss nur sortiert werden und liefert dann das Label mit den meißten Einträgen/Nachbarn zurück."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwB72vWW-9Yn",
        "outputId": "2c55e47b-8190-4e2e-cfb1-2a6fbce6ba41"
      },
      "source": [
        "#https://stackoverflow.com/questions/5900578/how-does-collections-defaultdict-work\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_label_count(neighbors):\n",
        "  countList=[]\n",
        "  \n",
        "  d = defaultdict(list)\n",
        "  for entfernung, label in neighbors:\n",
        "    d[label].append(entfernung)\n",
        "  \n",
        "  best_label =[]\n",
        "  for key in d:\n",
        "    best_label.append([key,len(d[key])])\n",
        "    \n",
        "    #print(key)\n",
        "    #print(d[key])\n",
        "    #print(len(d[key]))\n",
        "    #print(\"\")\n",
        "\n",
        "  best_label.sort(key=lambda x: x[1],reverse=True)\n",
        "\n",
        "  print(best_label)\n",
        "\n",
        "  return best_label[0]\n",
        "\n",
        "print(\"Funktion get_label_count wurde erstellt...\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Funktion get_label_count wurde erstellt...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aetfmF2kfR9n"
      },
      "source": [
        "## Lösung der Aufgabe\n",
        "\n",
        "Der folgende Code kann als Lösung der Aufgabe betrachtet werden. Er übergibt eine zuvor normailisierte Instanz an get_k_nearest. Das Ergebnis wird mit get_label_count ausgewerten und aufgeräumt ausgegeben.\n",
        "\n",
        "Die Zuordnung dreier bekannter Instanzen war erfolgreich. Das Auftauchen gleicher Werte im Array ist mit dem vorhandensein gleicher Basisdaten zu erklären.\n",
        "\n",
        "Natürlich währe die Lösung in einer IDE übersichtlicher und zudem das Problem mit wesendlich weniger Code lösbar. Aber ein Notebook ist ja auch ein Werkzeug, um sich Code und Daten flexible und dynamisch beschäftigen zu können."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q7LA7bgkmH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fafe5ba-d440-49b1-aef0-fb2197b87655"
      },
      "source": [
        "auftraege=normalizeSingleData(8)\n",
        "erfolgreich=normalizeSingleData(7)\n",
        "\n",
        "# 8/7 passt\n",
        "#12/8 passt\n",
        "# 4/4 passt\n",
        "\n",
        "# 8 entspricht in etwa der Wurzel aus 59\n",
        "# mit 8 kam es öfter mal zu Fehlern, 1 scheint die bessere Wahl\n",
        "x=get_k_nearest([auftraege,erfolgreich],10)\n",
        "y=get_label_count(x)\n",
        "\n",
        "print(\"Gesamtbild: \")\n",
        "print(\"\")\n",
        "\n",
        "print(\"Die 8 engsten Nachbarn sind: \")\n",
        "print(x)\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Die wahrscheinlichste Klasse ist: \" + str(y[0]) + \" mit \" + str(y[1]) + \" Mitgliedern\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.0, 8], [1.0, 3]]\n",
            "Gesamtbild: \n",
            "\n",
            "Die 8 engsten Nachbarn sind: \n",
            "[[0.03296703296703296, 2.0], [0.03296703296703296, 2.0], [0.03296703296703296, 2.0], [0.03296703296703296, 2.0], [0.03296703296703296, 2.0], [0.0786693465015184, 1.0], [0.0786693465015184, 1.0], [0.0786693465015184, 1.0], [0.0838699863872184, 2.0], [0.0838699863872184, 2.0], [0.0838699863872184, 2.0]]\n",
            "\n",
            "Die wahrscheinlichste Klasse ist: 2.0 mit 8 Mitgliedern\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}